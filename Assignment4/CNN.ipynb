{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Копия блокнота \"CNN.ipynb\"",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonarway/ML_HW/blob/main/Assignment4/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mrl-4G5-88bw"
      },
      "source": [
        "# Задание 4.1 - Сверточные нейронные сети (Convolutional Neural Networks)\n",
        "\n",
        "Это последнее задание на numpy, вы до него дожили! Остался последний марш-бросок, дальше только PyTorch.\n",
        "\n",
        "В этом задании вы реализуете свою собственную сверточную нейронную сеть."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLuCIsrT88b5",
        "outputId": "57ab13ba-f260-4535-bb78-902022251026"
      },
      "source": [
        "# Запустите эту ячейку если работаете в Colab\n",
        "!git clone https://github.com/sonarway/ML_HW.git\n",
        "%cd ML_HW/Assignment4\n",
        "!wget -c http://ufldl.stanford.edu/housenumbers/train_32x32.mat http://ufldl.stanford.edu/housenumbers/test_32x32.mat\n",
        "%cd ../Assignment4"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ML_HW'...\n",
            "remote: Enumerating objects: 96, done.\u001b[K\n",
            "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
            "remote: Compressing objects: 100% (78/78), done.\u001b[K\n",
            "remote: Total 96 (delta 32), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (96/96), done.\n",
            "/content/ML_HW/Assignment4\n",
            "--2021-03-25 17:50:48--  http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n",
            "Resolving ufldl.stanford.edu (ufldl.stanford.edu)... 171.64.68.10\n",
            "Connecting to ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 182040794 (174M) [text/plain]\n",
            "Saving to: ‘train_32x32.mat’\n",
            "\n",
            "train_32x32.mat     100%[===================>] 173.61M  62.3MB/s    in 2.8s    \n",
            "\n",
            "2021-03-25 17:50:51 (62.3 MB/s) - ‘train_32x32.mat’ saved [182040794/182040794]\n",
            "\n",
            "--2021-03-25 17:50:51--  http://ufldl.stanford.edu/housenumbers/test_32x32.mat\n",
            "Reusing existing connection to ufldl.stanford.edu:80.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64275384 (61M) [text/plain]\n",
            "Saving to: ‘test_32x32.mat’\n",
            "\n",
            "test_32x32.mat      100%[===================>]  61.30M  79.1MB/s    in 0.8s    \n",
            "\n",
            "2021-03-25 17:50:52 (79.1 MB/s) - ‘test_32x32.mat’ saved [64275384/64275384]\n",
            "\n",
            "FINISHED --2021-03-25 17:50:52--\n",
            "Total wall clock time: 3.6s\n",
            "Downloaded: 2 files, 235M in 3.6s (65.9 MB/s)\n",
            "/content/ML_HW/Assignment4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6nd1gji88b6"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJ2v8nvJ88b7"
      },
      "source": [
        "from dataset import load_svhn, random_split_train_val\n",
        "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
        "from layers import FullyConnectedLayer, ReLULayer, ConvolutionalLayer, MaxPoolingLayer, Flattener\n",
        "from model import ConvNet\n",
        "from trainer import Trainer, Dataset\n",
        "from optim import SGD, MomentumSGD\n",
        "from metrics import multiclass_accuracy"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbUvK3fz88b7"
      },
      "source": [
        "# Загружаем данные\n",
        "\n",
        "На этот раз мы не будем их преобразовывать в один вектор, а оставим размерности (num_samples, 32, 32, 3)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWLrVkPY88b7"
      },
      "source": [
        "def prepare_for_neural_network(train_X, test_X):    \n",
        "    train_X = train_X.astype(np.float) / 255.0\n",
        "    test_X = test_X.astype(np.float) / 255.0\n",
        "    \n",
        "    # Subtract mean\n",
        "    mean_image = np.mean(train_X, axis = 0)\n",
        "    train_X -= mean_image\n",
        "    test_X -= mean_image\n",
        "    \n",
        "    return train_X, test_X\n",
        "    \n",
        "train_X, train_y, test_X, test_y = load_svhn(\"../Assignment4\", max_train=10000, max_test=1000)    \n",
        "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
        "# Split train into train and val\n",
        "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGdvvVTs88b8"
      },
      "source": [
        "## Линейная свертка последовательностей\n",
        "\n",
        "Для начала вспомним, что сверткой последовательностей называется такая последовательность, в которой каждый элемент есть сумма перемноженных элементов двух числовых последовательностей $x$ длиной $N_1$ и $h$ длиной $N_2$ таким образом, что члены одной последовательности берутся с возрастанием индексов, а члены другой — с убыванием.\n",
        "\n",
        "$y_n = \\sum\\limits_{m=0}^n h_m \\cdot x_{n-m}$\n",
        "\n",
        "Такой же результат получится, если одну из последовательностей не сдвигать, а дополнить нулями с двух сторон.  \n",
        "Заметим, что для более \"похожих\" последовательностей значения свертки будут больше."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQz2Y0de88b8"
      },
      "source": [
        "<img src=\"https://github.com/sonarway/ML_HW/blob/main/Assignment4/img/conv1D.jpg?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM39OuYm88b9"
      },
      "source": [
        "## Двумерная свертка и max pooling\n",
        "\n",
        "\n",
        "Пусть мы имеем матрицу черно-белого изображения размером $6x6x1$. Нам нужно определить какая фигура на нем изображена: горизонтальная или вертикальная? Для этого мы используем два сверточных фильтра (Convolution Filters, kernels) размером $3x3$. На первом фильтре у нас три пикселя, расположенных вертикально, на втором фильтре три пикселя, расположенных горизонтально.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmAbUzBC88b9"
      },
      "source": [
        "<img src=\"https://github.com/sonarway/ML_HW/blob/main/Assignment4/img/conv2D_maxPool.jpg?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrirGrEv88b9"
      },
      "source": [
        "Сдвигая выбранный регион вдоль оси x и оси y мы получаем новую матрицу (карту) размером $4x4$ со значениями скалярного произведения сверточного фильтра и выбранного региона. Т.к. фильтра у нас два, то и сверточных карт у нас тоже будет две: $4x4x2$.  \n",
        "\n",
        "Далее, чтобы вычислить, на какой из фильтров больше \"похоже\" наше исходное изображение, применим операцию Max Pooling. Её смысл довольно прост - нужно из выбранного региона выбрать максимальное значение и записать его в выходную матрицу. Регионы так же как и в свертке сдвигаются вдоль оси x и y.  \n",
        "\n",
        "В результате получаем тензор $3x3x2$, который подается на вход полносвязного слоя, на выходе которого будет два скаляра - z-score для каждого класса. Для первого класса score будет выше, что говорит о том, что исходное изображение является скорее всего вертикальной полосой, чем горизонтальной.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf_b4z_T88b-"
      },
      "source": [
        "Заметим, что в результате свертки у нас уменьшился размер исходного изображения. В общем случае это недопустимо, поэтому исходное изображение дополняется по краям (padding) значениями 0 или ближайших пикселей."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dsvmteJ88b-"
      },
      "source": [
        "<img src=\"https://github.com/sonarway/ML_HW/blob/main/Assignment4/img/conv.gif?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7685oSC88b-"
      },
      "source": [
        "# Реализуем новые слои!\n",
        "\n",
        "Сначала основной новый слой - сверточный (Convolutional layer). \n",
        "\n",
        "На рисунке зеленым цветом обозначен один такой \"регион\", который скалярно перемножается с фильтром 1 (вертикальная полоска) и фильтром 2 (горизонтальная полоска)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmy3OrDT88b-"
      },
      "source": [
        "<img src=\"https://github.com/sonarway/ML_HW/blob/main/Assignment4/img/conv1.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78ZjsgUJ88b_"
      },
      "source": [
        "Он получает на вход   \n",
        "регион входа I размера `(batch_size, filter_size, filter_size, input_channels)`,  \n",
        "применяет к нему веса W `(filter_size, filter_size, input_channels, output_channels`\n",
        "и выдает `(batch_size, output_channels)`. \n",
        "\n",
        "Если:  \n",
        "- вход преобразовать в I' `(batch_size, filter_size*filter_size*input_channels)`,  \n",
        "- веса в W' `(filter_size*filter_size*input_channels, output_channels)`,  \n",
        "то выход \"пикселе\" будет эквивалентен полносвязному слою со входом I' и весами W'.\n",
        "\n",
        "Осталось выполнить его в цикле для каждого пикселя :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "HZUYxNCp88b_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5e82fc4-6e24-462d-a817-66510c3a55a0"
      },
      "source": [
        "# TODO: Implement ConvolutionaLayer that supports only 1 output and input channel\n",
        "\n",
        "# Note: now you're working with images, so X is 4-dimensional tensor of\n",
        "# (batch_size, height, width, channels)\n",
        "\n",
        "X = np.array([\n",
        "              [\n",
        "               [[1.0], [2.0]],\n",
        "               [[0.0], [-1.0]]\n",
        "              ]\n",
        "              ,\n",
        "              [\n",
        "               [[0.0], [1.0]],\n",
        "               [[-2.0], [-1.0]]\n",
        "              ]\n",
        "             ])\n",
        "\n",
        "# Batch of 2 images of dimensions 2x2 with a single channel\n",
        "print(\"Shape of X:\",X.shape)\n",
        "\n",
        "layer = ConvolutionalLayer(in_channels=1, out_channels=1, filter_size=2, padding=0)\n",
        "print(\"Shape of W\", layer.W.value.shape)\n",
        "layer.W.value = np.zeros_like(layer.W.value)\n",
        "layer.W.value[0, 0, 0, 0] = 1.0\n",
        "layer.B.value = np.ones_like(layer.B.value)\n",
        "result = layer.forward(X)\n",
        "\n",
        "assert result.shape == (2, 1, 1, 1)\n",
        "assert np.all(result == X[:, :1, :1, :1] +1), \"result: %s, X: %s\" % (result, X[:, :1, :1, :1])\n",
        "\n",
        "\n",
        "# Now let's implement multiple output channels\n",
        "layer = ConvolutionalLayer(in_channels=1, out_channels=2, filter_size=2, padding=0)\n",
        "result = layer.forward(X)\n",
        "assert result.shape == (2, 1, 1, 2)\n",
        "\n",
        "\n",
        "# And now multple input channels!\n",
        "X = np.array([\n",
        "              [\n",
        "               [[1.0, 0.0], [2.0, 1.0]],\n",
        "               [[0.0, -1.0], [-1.0, -2.0]]\n",
        "              ]\n",
        "              ,\n",
        "              [\n",
        "               [[0.0, 1.0], [1.0, -1.0]],\n",
        "               [[-2.0, 2.0], [-1.0, 0.0]]\n",
        "              ]\n",
        "             ])\n",
        "\n",
        "print(\"Shape of X:\", X.shape)\n",
        "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
        "result = layer.forward(X)\n",
        "assert result.shape == (2, 1, 1, 2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X: (2, 2, 2, 1)\n",
            "Shape of W (2, 2, 1, 1)\n",
            "Shape of X: (2, 2, 2, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QjtNgU_88cA"
      },
      "source": [
        "## А теперь имплементируем обратный проход\n",
        "Возможно, это самое сложное место в курсе. Дальше будет лучше.\n",
        "\n",
        "Раз выполнение сверточного слоя эквивалентно полносвязному слою для каждого \"пикселя\" выхода, то общий обратный проход эквивалентен обратному проходу каждого из таких \"слоев\".  \n",
        "Градиенты от каждого из этих \"слоев\" в каждом пикселе надо сложить в соответствующие пиксели градиента по входу, а градиенты весов сложить все вместе."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "5jP1d5LN88cB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aca33e5-0233-4cda-9aaf-1493bdd67f46"
      },
      "source": [
        "# First test - check the shape is right\n",
        "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
        "result = layer.forward(X)\n",
        "d_input = layer.backward(np.ones_like(result))\n",
        "assert d_input.shape == X.shape\n",
        "\n",
        "# Actually test the backward pass\n",
        "# As usual, you'll need to copy gradient check code from the previous assignment\n",
        "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
        "assert check_layer_gradient(layer, X)\n",
        "\n",
        "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
        "assert check_layer_param_gradient(layer, X, 'W')\n",
        "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
        "assert check_layer_param_gradient(layer, X, 'B')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradient check passed!\n",
            "Gradient check passed!\n",
            "Gradient check passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbqAGBMc88cB"
      },
      "source": [
        "Осталось реализовать дополнение нулями (padding).   \n",
        "Достаточно дополнить входной тензор нулями по сторонам. Не забудьте учесть это при обратном проходе!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "nkoizKe588cB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcdcbae1-ed1c-4ceb-8e55-cb378e5eaf12"
      },
      "source": [
        "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=3, padding=1)\n",
        "result = layer.forward(X)\n",
        "# Note this kind of layer produces the same dimensions as input\n",
        "assert result.shape == X.shape,\"Result shape: %s - Expected shape %s\" % (result.shape, X.shape)\n",
        "d_input = layer.backward(np.ones_like(result))\n",
        "assert d_input.shape == X.shape\n",
        "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=3, padding=1)\n",
        "assert check_layer_gradient(layer, X)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradient check passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxmIIk_I88cC"
      },
      "source": [
        "## После следующего слоя вам уже будет все ни по чем - max pooling\n",
        "\n",
        "Max Pooling - это слой, реализующий операцию максимума для каждого канала отдельно в окресности из `pool_size` \"пикселей\".\n",
        "\n",
        "![image](https://upload.wikimedia.org/wikipedia/commons/e/e9/Max_pooling.png)\n",
        "\n",
        "И напомним что такое stride.  \n",
        "Stride - это на сколько \"пикселей\" сдвигается окно на одном шаге.  \n",
        "Вот здесь, например, stride = 2\n",
        "\n",
        "![image.png](http://deeplearning.net/software/theano/_images/no_padding_strides.gif)\n",
        "\n",
        "На практике, для max pooling значение stride часто равно pool size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_uOn9fh88cC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ef2ad11-3905-466e-c7bd-aa3b10ad35b6"
      },
      "source": [
        "pool = MaxPoolingLayer(2, 2)\n",
        "result = pool.forward(X)\n",
        "assert result.shape == (2, 1, 1, 2)\n",
        "\n",
        "assert check_layer_gradient(pool, X)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradient check passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga4gBsIY88cC"
      },
      "source": [
        "И на закуску - слой, преобразующий четырехмерные тензоры в двумерные.\n",
        "\n",
        "Этот слой понадобится нам, чтобы в конце сети перейти от сверточных слоев к полносвязным."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuH6G3U988cD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93c81312-24a7-4040-bc66-846f65b6c13d"
      },
      "source": [
        "flattener = Flattener()\n",
        "result = flattener.forward(X)\n",
        "assert result.shape == (2,8)\n",
        "\n",
        "assert check_layer_gradient(flattener, X)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradient check passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lp8GEDD88cD"
      },
      "source": [
        "# Теперь есть все кирпичики, создаем модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "hflf_YW088cD"
      },
      "source": [
        "# TODO: In model.py, implement missed functions function for ConvNet model\n",
        "\n",
        "# No need to use L2 regularization\n",
        "model = ConvNet(input_shape=(32,32,3), n_output_classes=10, conv1_channels=2, conv2_channels=2)\n",
        "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
        "\n",
        "# TODO Now implement backward pass and aggregate all of the params\n",
        "check_model_gradient(model, train_X[:2], train_y[:2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1ktbLT288cD"
      },
      "source": [
        "# Оптимизатор и код для тренировки \n",
        "Должен заработать с кодом из прошлого задания без изменений!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "L4NCWgSp88cD"
      },
      "source": [
        "model = ConvNet(input_shape=(32,32,3), n_output_classes=10, conv1_channels=2, conv2_channels=2)\n",
        "dataset = Dataset(train_X[:16], train_y[:16], val_X[:16], val_y[:16])\n",
        "trainer = Trainer(model, dataset, SGD(), batch_size=16, learning_rate=1e-4)\n",
        "\n",
        "loss_history, train_history, val_history = trainer.fit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UZfOEXC88cE"
      },
      "source": [
        "plt.plot(train_history)\n",
        "plt.plot(val_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-LFrIia88cE"
      },
      "source": [
        "# Последнее упражнение\n",
        "В качестве последнего упражнения мы доведем точность на тренировочном наборе данных до 100% на небольшом наборе данных.\n",
        "Сверточные сети требуют большого количества вычислений и аккуратной эффективной реализации, поэтому настоящие модели мы будем тренировать уже на PyTorch в следующем задании."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-yKx0Am88cE"
      },
      "source": [
        "## Итак, оверфитим маленький набор данных\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_Ua57qU88cE"
      },
      "source": [
        "data_size = 128\n",
        "model = ConvNet(input_shape=(32,32,3), n_output_classes=10, conv1_channels=2, conv2_channels=2)\n",
        "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
        "# TODO: Change any hyperparamers or optimizators to reach 1.0 training accuracy in 50 epochs or less\n",
        "# Hint: If you have hard time finding the right parameters manually, try grid search or random search!\n",
        "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-5, num_epochs=50, batch_size=64)\n",
        "\n",
        "loss_history, train_history, val_history = trainer.fit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbsMqoR988cF"
      },
      "source": [
        "plt.plot(train_history)\n",
        "plt.plot(val_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxBWNcXV88cF"
      },
      "source": [
        "Дальнейшие упражнения - уже на PyTorch, открывайте следующий notebook!\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52hMNDCg88cH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}